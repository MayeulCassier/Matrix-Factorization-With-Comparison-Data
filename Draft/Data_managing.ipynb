{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is the code to discover the datas and format them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users DataFrame:\n",
      "   user_id  age gender  occupation zip_code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n",
      "Users shape: (943, 5)\n",
      "\n",
      "Movies DataFrame:\n",
      "   movie_id              title\n",
      "0         1   Toy Story (1995)\n",
      "1         2   GoldenEye (1995)\n",
      "2         3  Four Rooms (1995)\n",
      "3         4  Get Shorty (1995)\n",
      "4         5     Copycat (1995)\n",
      "Movies shape: (1682, 24)\n",
      "\n",
      "Ratings DataFrame:\n",
      "   user_id  movie_id  rating  timestamp\n",
      "0      196       242       3  881250949\n",
      "1      186       302       3  891717742\n",
      "2       22       377       1  878887116\n",
      "3      244        51       2  880606923\n",
      "4      166       346       1  886397596\n",
      "Ratings shape: (100000, 4)\n",
      "\n",
      "SVM-ready DataFrame:\n",
      "   user_id  movie_id  rating  timestamp                       title  age  \\\n",
      "0      196       242       3  881250949                Kolya (1996)   49   \n",
      "1      186       302       3  891717742    L.A. Confidential (1997)   39   \n",
      "2       22       377       1  878887116         Heavyweights (1994)   25   \n",
      "3      244        51       2  880606923  Legends of the Fall (1994)   28   \n",
      "4      166       346       1  886397596         Jackie Brown (1997)   47   \n",
      "\n",
      "  gender  \n",
      "0      M  \n",
      "1      F  \n",
      "2      M  \n",
      "3      M  \n",
      "4      M  \n",
      "SVM data shape: (100000, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from helpers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load and display the data\n",
    "data_users, data_items, data_ratings = load_movielens_data()\n",
    "\n",
    "# Useful subsets for SVM algorithm\n",
    "svm_data = data_ratings.merge(data_items[['movie_id', 'title']], on='movie_id').merge(data_users[['user_id', 'age', 'gender']], on='user_id')\n",
    "\n",
    "print(\"\\nSVM-ready DataFrame:\")\n",
    "print(svm_data.head())\n",
    "print(f\"SVM data shape: {svm_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mayeul\\AppData\\Local\\Temp\\ipykernel_9112\\1328305061.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered['preference'] = (filtered['rating_j'] > filtered['rating_k']).astype(int) * 2 - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (16080649, 3)\n",
      "Test data shape: (4020163, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import NamedTuple, List, Dict, Tuple\n",
    "class PairwiseDataset(NamedTuple):\n",
    "    \"\"\"Data container for pairwise comparisons\"\"\"\n",
    "    users: np.ndarray\n",
    "    movie_j: np.ndarray\n",
    "    movie_k: np.ndarray\n",
    "    preferences: np.ndarray\n",
    "\n",
    "def create_pairwise_dataset(svm_data):\n",
    "    # Créer une jointure auto-corrélée pour générer les comparaisons par paires\n",
    "    merged = svm_data[['user_id', 'movie_id', 'rating']].merge(\n",
    "        svm_data[['user_id', 'movie_id', 'rating']],\n",
    "        on='user_id',\n",
    "        suffixes=('_j', '_k')\n",
    "    )\n",
    "\n",
    "    # Filtrer les paires où les films sont différents\n",
    "    filtered = merged[merged['movie_id_j'] != merged['movie_id_k']]\n",
    "\n",
    "    # Ajouter la colonne de préférence\n",
    "    filtered['preference'] = (filtered['rating_j'] > filtered['rating_k']).astype(int) * 2 - 1\n",
    "\n",
    "    # Extraire les colonnes pertinentes\n",
    "    df = filtered[['user_id', 'movie_id_j', 'movie_id_k', 'preference']]\n",
    "\n",
    "    return PairwiseDataset(\n",
    "        users=df['user_id'].values,\n",
    "        movie_j=df['movie_j_id'].values,\n",
    "        movie_k=df['movie_k_id'].values,\n",
    "        preferences=df['preference'].values\n",
    "    )\n",
    "\n",
    "def split_pairwise_dataset(dataset, p_test=0.1, seed=1):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    test_mask = rng.uniform(size=len(dataset.preferences)) < p_test\n",
    "    train_mask = ~test_mask\n",
    "\n",
    "    train_data = PairwiseDataset(\n",
    "        users=dataset.users[train_mask],\n",
    "        movie_j=dataset.movie_j[train_mask],\n",
    "        movie_k=dataset.movie_k[train_mask],\n",
    "        preferences=dataset.preferences[train_mask],\n",
    "    )\n",
    "    test_data = PairwiseDataset(\n",
    "        users=dataset.users[test_mask],\n",
    "        movie_j=dataset.movie_j[test_mask],\n",
    "        movie_k=dataset.movie_k[test_mask],\n",
    "        preferences=dataset.preferences[test_mask],\n",
    "    )\n",
    "    return train_data, test_data\n",
    "\n",
    "def mse(predictions, targets):\n",
    "    return np.mean((predictions - targets) ** 2)\n",
    "\n",
    "class AltSVMPairwisePredictor:\n",
    "    def __init__(self, train_data: PairwiseDataset, num_features=20, seed=1):\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        num_users = np.max(train_data.users) + 1\n",
    "        num_movies = max(np.max(train_data.movie_j), np.max(train_data.movie_k)) + 1\n",
    "\n",
    "        self.user_features = rng.normal(size=[num_users, num_features])\n",
    "        self.movie_features = rng.normal(size=[num_movies, num_features])\n",
    "\n",
    "    def __call__(self, test_data: PairwiseDataset):\n",
    "        u = self.user_features[test_data.users]\n",
    "        v_j = self.movie_features[test_data.movie_j]\n",
    "        v_k = self.movie_features[test_data.movie_k]\n",
    "        return np.sum(u * (v_j - v_k), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_alt_svm(train_data: PairwiseDataset, test_data: PairwiseDataset, num_features=20, user_reg=20, movie_reg=20, max_iter=1000, stop_crit=1e-4):\n",
    "    predictor = AltSVMPairwisePredictor(train_data, num_features)\n",
    "    user_features = predictor.user_features\n",
    "    movie_features = predictor.movie_features\n",
    "\n",
    "    prev_train_error = None\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        # Update user features\n",
    "        for user in np.unique(train_data.users):\n",
    "            mask = train_data.users == user\n",
    "            v_diff = predictor.movie_features[train_data.movie_j[mask]] - predictor.movie_features[train_data.movie_k[mask]]\n",
    "            r = train_data.preferences[mask]\n",
    "            user_features[user] = np.linalg.solve(v_diff.T @ v_diff + np.eye(num_features) * user_reg, v_diff.T @ r)\n",
    "\n",
    "        # Update movie features\n",
    "        for movie in np.unique(np.concatenate((train_data.movie_j, train_data.movie_k))):\n",
    "            mask_j = train_data.movie_j == movie\n",
    "            mask_k = train_data.movie_k == movie\n",
    "\n",
    "            u_j = user_features[train_data.users[mask_j]]\n",
    "            r_j = train_data.preferences[mask_j]\n",
    "\n",
    "            u_k = -user_features[train_data.users[mask_k]]\n",
    "            r_k = -train_data.preferences[mask_k]\n",
    "\n",
    "            u_combined = np.vstack((u_j, u_k))\n",
    "            r_combined = np.concatenate((r_j, r_k))\n",
    "\n",
    "            movie_features[movie] = np.linalg.solve(u_combined.T @ u_combined + np.eye(num_features) * movie_reg, u_combined.T @ r_combined)\n",
    "\n",
    "        train_error = mse(predictor(train_data), train_data.preferences)\n",
    "        test_error = mse(predictor(test_data), test_data.preferences)\n",
    "        print(f\"Iteration {iteration+1}: Train Error: {train_error:.4f}, Test Error: {test_error:.4f}\")\n",
    "\n",
    "        if prev_train_error is not None and abs(train_error - prev_train_error) < stop_crit:\n",
    "            break\n",
    "        prev_train_error = train_error\n",
    "\n",
    "    return predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class AltSVMPairwisePredictor:\n",
    "    def __init__(self, train_data, num_features=20, seed=1):\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        num_users = np.max(train_data.users) + 1\n",
    "        num_movies = max(np.max(train_data.movie_j), np.max(train_data.movie_k)) + 1\n",
    "\n",
    "        self.user_features = rng.normal(size=[num_users, num_features])\n",
    "        self.movie_features = rng.normal(size=[num_movies, num_features])\n",
    "        self.alpha = np.zeros(len(train_data.preferences))\n",
    "        self.beta = np.zeros(len(train_data.preferences))\n",
    "\n",
    "    def __call__(self, test_data):\n",
    "        u = self.user_features[test_data.users]\n",
    "        v_j = self.movie_features[test_data.movie_j]\n",
    "        v_k = self.movie_features[test_data.movie_k]\n",
    "        return np.sum(u * (v_j - v_k), axis=1)\n",
    "\n",
    "    def train(self, train_data, lambda_reg=0.1, num_epochs=10, learning_rate=0.01, S=5, T=4):\n",
    "        \"\"\"Train the AltSVM model using pairwise comparison data with delta updates\"\"\"\n",
    "        for epoch in range(num_epochs):\n",
    "            # Update item features V\n",
    "            for j in range(len(self.movie_features)):\n",
    "                # Compute the first sum (positive part)\n",
    "                positive_indices = (train_data.movie_j == j)\n",
    "                positive_sum = np.sum(\n",
    "                    [self.beta[idx] * train_data.preferences[idx] * self.user_features[train_data.users[idx]]\n",
    "                    for idx in np.where(positive_indices)[0]], axis=0\n",
    "                )\n",
    "\n",
    "                # Compute the second sum (negative part)\n",
    "                negative_indices = (train_data.movie_k == j)\n",
    "                negative_sum = np.sum(\n",
    "                    [self.beta[idx] * train_data.preferences[idx] * self.user_features[train_data.users[idx]]\n",
    "                    for idx in np.where(negative_indices)[0]], axis=0\n",
    "                )\n",
    "\n",
    "                # Update movie feature with both sums\n",
    "                self.movie_features[j] = positive_sum - negative_sum\n",
    "\n",
    "            # Parallel block for beta updates\n",
    "            for _ in range(T):\n",
    "                for _ in range(S):\n",
    "                    idx = np.random.choice(len(train_data.preferences))\n",
    "                    i, j, k, pref = train_data.users[idx], train_data.movie_j[idx], train_data.movie_k[idx], train_data.preferences[idx]\n",
    "                    u_vec = self.user_features[i]\n",
    "                    v_j = self.movie_features[j]\n",
    "                    v_k = self.movie_features[k]\n",
    "\n",
    "                    # Compute delta minimizing equation (10)\n",
    "                    pred = np.dot(u_vec, v_j - v_k)\n",
    "                    delta = pref - pred\n",
    "                    self.beta[idx] += delta\n",
    "                    self.movie_features[j] += delta * pref * u_vec\n",
    "                    self.movie_features[k] -= delta * pref * u_vec\n",
    "\n",
    "            # Update user features U\n",
    "            for i in range(len(self.user_features)):\n",
    "                relevant_indices = (train_data.users == i)\n",
    "                self.user_features[i] = np.sum(\n",
    "                    [self.alpha[idx] * train_data.preferences[idx] * (self.movie_features[train_data.movie_j[idx]] - self.movie_features[train_data.movie_k[idx]])\n",
    "                     for idx in np.where(relevant_indices)[0]], axis=0\n",
    "                )\n",
    "\n",
    "            # Parallel block for alpha updates\n",
    "            for _ in range(T):\n",
    "                for _ in range(S):\n",
    "                    idx = np.random.choice(len(train_data.preferences))\n",
    "                    i, j, k, pref = train_data.users[idx], train_data.movie_j[idx], train_data.movie_k[idx], train_data.preferences[idx]\n",
    "                    v_j = self.movie_features[j]\n",
    "                    v_k = self.movie_features[k]\n",
    "\n",
    "                    # Compute delta minimizing equation (8)\n",
    "                    pred = np.dot(self.user_features[i], v_j - v_k)\n",
    "                    delta = pref - pred\n",
    "                    self.alpha[idx] += delta\n",
    "                    self.user_features[i] += delta * pref * (v_j - v_k)\n",
    "\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs} completed\")\n",
    "\n",
    "        print(\"Training completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from test_utils import test\n",
    "from typing import NamedTuple, List, Dict, Tuple\n",
    "\n",
    "data = scipy.io.loadmat(\"movielens100k.mat\")[\"ratings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(NamedTuple):\n",
    "    \"\"\"Data container with three arrays of the same length:\"\"\"\n",
    "\n",
    "    movies: np.ndarray\n",
    "    users: np.ndarray\n",
    "    ratings: np.ndarray\n",
    "\n",
    "\n",
    "def load_data() -> Dataset:\n",
    "    \"\"\"Load a sparse matrix from a matlab file and return is as a list of\"\"\"\n",
    "    data = scipy.io.loadmat(\"movielens100k.mat\")[\"ratings\"]\n",
    "    movies, users = data.nonzero()  # indices of available ratings in the matrix\n",
    "    ratings = data[movies, users].A1\n",
    "    return Dataset(movies, users, ratings)\n",
    "\n",
    "\n",
    "dataset = load_data()\n",
    "\n",
    "num_users = np.max(dataset.users) + 1\n",
    "num_movies = np.max(dataset.movies) + 1\n",
    "\n",
    "print(\n",
    "    f\"Loaded {len(dataset.ratings)} ratings of {num_users} users for {num_movies} movies.\"\n",
    ")\n",
    "def split_dataset(dataset, p_test=0.1, seed=1):\n",
    "    \"\"\"\n",
    "    Split a dataset randomly into a train and a test part\n",
    "\n",
    "    Inputs:\n",
    "        dataset: Dataset\n",
    "        p_test: float\n",
    "            propability (0 < p_test < 1) for a data point to go into the test set\n",
    "        seed: integer\n",
    "\n",
    "    Returns:\n",
    "        train_dataset: Dataset\n",
    "        test_dataset: Dataset\n",
    "\n",
    "    >>> split_dataset(Dataset(np.array([0, 0]), np.array([1, 0]), np.array([2.0, 1.0])), p_test=0)\n",
    "    (Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])), Dataset(movies=array([], dtype=int64), users=array([], dtype=int64), ratings=array([], dtype=float64)))\n",
    "\n",
    "    >>> split_dataset(Dataset(np.array([0, 0]), np.array([1, 0]), np.array([2.0, 1.0])), p_test=1)\n",
    "    (Dataset(movies=array([], dtype=int64), users=array([], dtype=int64), ratings=array([], dtype=float64)), Dataset(movies=array([0, 0]), users=array([1, 0]), ratings=array([2., 1.])))\n",
    "    \"\"\"\n",
    "    # use this generator (https://numpy.org/doc/stable/reference/random/index.html)\n",
    "    # you should use rng.uniform() once inside this function to match the automatic test case\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    ### SOLUTION\n",
    "    test_mask = rng.uniform(size=len(dataset.ratings)) < p_test\n",
    "    train_mask = ~test_mask  # invert the mask\n",
    "\n",
    "    movies, users, ratings = dataset\n",
    "\n",
    "    train_data = Dataset(movies[train_mask], users[train_mask], ratings[train_mask])\n",
    "    test_data = Dataset(movies[test_mask], users[test_mask], ratings[test_mask])\n",
    "    ### END SOLUTION\n",
    "\n",
    "    return train_data, test_data\n",
    "train_data, test_data = split_dataset(pruned_dataset, p_test=0.1, seed=10)\n",
    "print(\"Number of training points:\", len(train_data.ratings))\n",
    "print(\"Number of test points:\", len(test_data.ratings))\n",
    "def to_matrix(dataset, num_movies, num_users):\n",
    "    \"\"\"\n",
    "    Construct a dense matrix out of the dataset.\n",
    "\n",
    "    Input:\n",
    "        dataset: Dataset\n",
    "\n",
    "    Output:\n",
    "        matrix: np.array of floats: (# movies, # users) -> rating (float) or np.NaN if unavailable\n",
    "\n",
    "    >>> to_matrix(Dataset(np.array([1, 1, 0]), np.array([0, 1, 0]), np.array([1.0, 3.0, 2.5])), 3, 2)\n",
    "    array([[2.5, nan],\n",
    "           [1. , 3. ],\n",
    "           [nan, nan]])\n",
    "    \"\"\"\n",
    "    m = (\n",
    "        np.zeros([num_movies, num_users]) * np.NaN\n",
    "    )  # We want NaNs for unavailable ratings\n",
    "    ### SOLUTION\n",
    "    if len(dataset.ratings) > 0:\n",
    "        m[dataset.movies, dataset.users] = dataset.ratings\n",
    "    ### END SOLUTION\n",
    "    ### HINT: Edit `m` by filling in the available ratings\n",
    "    return m\n",
    "\n",
    "class MatrixFactorizationPredictor(Predictor):\n",
    "    def __init__(self, train_data: Dataset, num_features=20, seed=1):\n",
    "        # Randomly initialize features for the users and the movies from N(0, 1)\n",
    "\n",
    "        # use this generator (https://numpy.org/doc/stable/reference/random/index.html)\n",
    "        # you are expected to use rng.normal() twice in this function to match the tests, once for movies, and then once for users\n",
    "        rng = np.random.default_rng(seed)\n",
    "\n",
    "        num_movies = np.max(train_data.movies) + 1\n",
    "        num_users = np.max(train_data.users) + 1\n",
    "        ### SOLUTION\n",
    "        self.movie_features = rng.normal(size=[num_movies, num_features])\n",
    "        self.user_features = rng.normal(size=[num_users, num_features])\n",
    "        ### END SOLUTION\n",
    "\n",
    "        # Normally, you should train the model here, but we will skip this\n",
    "        # for now, to be able to take it step-by-step.\n",
    "\n",
    "    def __call__(self, test_data: Dataset):\n",
    "        \"\"\"\n",
    "        Predict the rating of a user/movie pair as the dot-product\n",
    "        of representation vectors of the user and the movie.\n",
    "\n",
    "        >>> train_data = Dataset(np.array([0, 0, 1, 1, 2]), np.array([1, 2, 3, 4, 5]), np.array([4.0, 1.0, 1.0, 2.0, 1.0]))\n",
    "        >>> test_data = Dataset(np.array([0, 1, 2, 1]), np.array([1, 2, 2, 0]), np.array([1.0, 2.0, 2.5, 5.0]))\n",
    "        >>> mean_predictor = MatrixFactorizationPredictor(train_data)\n",
    "        >>> mean_predictor(test_data)  # the factorization is not yet optimized here\n",
    "        array([ 2.62654714, -2.89866225,  0.70909287,  5.29901482])\n",
    "        \"\"\"\n",
    "        ### SOLUTION\n",
    "        user_features = self.user_features[test_data.users]\n",
    "        movie_features = self.movie_features[test_data.movies]\n",
    "        return (user_features * movie_features).sum(axis=1)\n",
    "        ### END SOLUTION\n",
    "movie_regularization = 20\n",
    "user_regularization = 20\n",
    "max_iterations = 1000\n",
    "stop_criterion = 1e-4\n",
    "\n",
    "predictor = MatrixFactorizationPredictor(train_data)\n",
    "user_features = predictor.user_features\n",
    "movie_features = predictor.movie_features\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "prev_train_error = None\n",
    "\n",
    "for iteration in range(max_iterations):\n",
    "    # Optimize the user features\n",
    "    for user in np.unique(train_data.users):\n",
    "        # Update `user_features[user]` by optimizing the regularized corresponding least squares objective\n",
    "        mask = train_data.users == user\n",
    "        user_movies = train_data.movies[mask]\n",
    "        ### SOLUTION\n",
    "        M = movie_features[user_movies]\n",
    "        r = train_data.ratings[mask]\n",
    "        user_features[user] = np.linalg.solve(\n",
    "            M.T @ M + np.eye(M.shape[1]) * user_regularization, M.T @ r\n",
    "        )\n",
    "        ### END SOLUTION\n",
    "\n",
    "    # Optimize the movie features using least squares\n",
    "    for movie in np.unique(train_data.movies):\n",
    "        # Update `movie_features[movie]` by optimizing the regularized corresponding least squares objective\n",
    "        mask = train_data.movies == movie\n",
    "        movie_users = train_data.users[mask]\n",
    "        ### SOLUTION\n",
    "        M = user_features[movie_users]\n",
    "        r = train_data.ratings[mask]\n",
    "        movie_features[movie] = np.linalg.solve(\n",
    "            M.T @ M + np.eye(M.shape[1]) * movie_regularization, M.T @ r\n",
    "        )\n",
    "        ### END SOLUTION\n",
    "\n",
    "    train_error = mse(predictor(train_data), train_data.ratings)\n",
    "    print(f\"Train error after step {iteration+1}: {train_error}\")\n",
    "    print(\n",
    "        f\"Test error after step {iteration+1}: {mse(predictor(test_data), test_data.ratings)}\"\n",
    "    )\n",
    "\n",
    "    # Stop if the training error is not going down more than 'stop_criterion'\n",
    "    ### SOLUTION\n",
    "    if (\n",
    "        prev_train_error is not None\n",
    "        and np.abs(train_error - prev_train_error) < stop_criterion\n",
    "    ):\n",
    "        break\n",
    "    prev_train_error = train_error\n",
    "    ### END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
