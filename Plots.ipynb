{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53710bfd",
   "metadata": {},
   "source": [
    "# Here is the file for the plots\n",
    "This notebook summarizes and visualizes the behavior of various metrics under different matrix factorization settings.\n",
    "The plots cover how accuracy, reconstruction error, and correlation metrics evolve depending on the sampling rate `p`, the number of latent dimensions `d`, the scaling factor `s`, and selection strategies.\n",
    "Some sections also analyze the distribution of per-row metrics and the influence of outliers or structured noise.\n",
    "\n",
    "No comments are made on this notebook directly. Please refer to the pdf for more details.\n",
    "\n",
    "## Summary\n",
    "\n",
    "- [Plots vs $s$](#plots-vs-s)\n",
    "  - [Plots vs $s$ by $p$](#plots-vs-s-by-p)\n",
    "  - [Plots vs $s$ by $k$](#plots-vs-s-by-k)\n",
    "- [Plots explaining the difference in Reconstruction Error Scaled per Row and the Pearson coefficient](#plots-explaining-the-difference-in-reconstruction-error-scaled-per-row-and-the-pearson-coefficient)\n",
    "  - [Comparison of the distribution of the values per row](#comparison-of-the-distribution-of-the-values-per-row)\n",
    "  - [Histogram of the distribution of the $\\alpha_u$](#histogram-of-the-distribution-of-the-alpha_u)\n",
    "  - [Effect of the outlier and of the noise on the metrics](#effect-of-the-outlier-and-of-the-noise-on-the-metrics)\n",
    "  - [Plots for $p \\cdot k = \\text{const}$](#plots-for-p-cdot-k-const)\n",
    "- [Plots vs $p$](#plots-vs-p)\n",
    "  - [Plots for $p \\cdot s = \\text{const}$](#plots-for-p-cdot-s--const)\n",
    "  - [Plots for $p$ vs $d$](#plots-for-p-vs-d)\n",
    "- [Plots for Strategies](#plots-for-strategies)\n",
    "  - [Plots for strategies vs $s$](#plots-for-strategies-vs-s)\n",
    "  - [Plots for strategies vs $p$](#plots-for-strategies-vs-p)\n",
    "- [Plots for Ground Truth Analysis](#plots-for-ground-truth-analysis)\n",
    "  - [Plots vs $p$](#plots-vs-p-1)\n",
    "  - [Plots vs $d$](#plots-vs-d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34084d0",
   "metadata": {},
   "source": [
    "# Plots vs $s$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1bf0c",
   "metadata": {},
   "source": [
    "## Plots vs $s$ by $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8dd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from visualization import plot_metrics_vs_param, display_experiment_indices\n",
    "\n",
    "# === Load results from latest experiment ===\n",
    "file_path_1 = \"Data_final/scan_K1_fixedLR_varS_varP_full_4.pkl\"\n",
    "with open(file_path_1, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# === Plot: Accuracy vs s (grouped by p), over full range, for all weight_decay values ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/accuracy_vs_s_by_p_full\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Filter: only results with weight_decay = 5e-6, then plot reconstruction error vs s ===\n",
    "result_4 = [exp for exp in results if exp[\"params\"][\"weight_decay\"] == 5e-6]\n",
    "plot_metrics_vs_param(\n",
    "    results=result_4,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    "    save_path=\"Results_final/reconstruction_error_vs_s_by_p_full\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Filter: results in reasonable s range (0.1 ≤ s ≤ 100), for clarity in plots ===\n",
    "results_2 = [exp for exp in results if 0.1 <= exp[\"params\"][\"s\"] <= 100]\n",
    "\n",
    "# === Plot: Accuracy vs s for filtered s-range ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_2,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/accuracy_vs_s_by_p\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Plot: Reconstruction error vs s for filtered s-range ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_2,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    "    save_path=\"Results_final/reconstruction_error_vs_s_by_p\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Filter: same s-range and weight_decay = 5e-6 ===\n",
    "results_5 = [exp for exp in results if exp[\"params\"][\"weight_decay\"] == 5e-6 and 0.1 <= exp[\"params\"][\"s\"] <= 100]\n",
    "\n",
    "# === Plot: Reconstruction error vs s with weight_decay fixed ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_5,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    "    save_path=\"Results_final/reconstruction_error_vs_s_by_p_wd_fixed\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Add 'final_loss' metric if missing (last validation loss) ===\n",
    "for exp in results:\n",
    "    if \"final_loss\" not in exp[\"results\"]:\n",
    "        exp[\"results\"][\"final_loss\"] = exp[\"results\"][\"val_losses\"][-1]\n",
    "\n",
    "# === Plot: Final validation loss vs s for all experiments ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"final_loss\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/final_loss_vs_s_by_p_full\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc91698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem\n",
    "from matplotlib import colors as mcolors\n",
    "from visualization import (\n",
    "    plot_metrics_vs_param,\n",
    "    plot_optimal_param_vs_x,\n",
    "    smart_formatter\n",
    ")\n",
    "\n",
    "# === Load experiment results ===\n",
    "file_path_1 = \"Data_final/scan_K1_fixedLR_varS_varP_full_4.pkl\"\n",
    "with open(file_path_1, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# === Create two separate copies of results to simulate wd fixed vs optimized ===\n",
    "results_one_wd = [copy.deepcopy(exp) for exp in results if exp[\"params\"][\"weight_decay\"] == 5e-6 and exp[\"params\"][\"p\"] in [0.1, 0.2, 0.5]]\n",
    "results_other = [copy.deepcopy(exp) for exp in results if exp[\"params\"][\"p\"] in [0.1, 0.2, 0.5]]\n",
    "\n",
    "# === Assign labels for grouping in plots ===\n",
    "for exp in results_one_wd:\n",
    "    exp[\"params\"][\"wd\"] = \"$10^{-5}$\"\n",
    "for exp in results_other:\n",
    "    exp[\"params\"][\"wd\"] = \"Optimized\"\n",
    "\n",
    "# === Merge both sets for potential group plotting ===\n",
    "results_3 = results_one_wd + results_other\n",
    "\n",
    "# === Compute best reconstruction error per s for each p (optimized wd only) ===\n",
    "grouped_by_p = defaultdict(list)\n",
    "for exp in results_other:\n",
    "    p = exp[\"params\"][\"p\"]\n",
    "    grouped_by_p[p].append(exp)\n",
    "\n",
    "p_to_s_best = {}\n",
    "for p, exps in grouped_by_p.items():\n",
    "    s_to_errors = defaultdict(list)\n",
    "    for exp in exps:\n",
    "        s = exp[\"params\"][\"s\"]\n",
    "        s_to_errors[s].append(exp[\"results\"][\"reconstruction_errors\"])\n",
    "\n",
    "    s_best_vals = {}\n",
    "    for s, error_lists in s_to_errors.items():\n",
    "        best_mean = float(\"inf\")\n",
    "        best_sem = None\n",
    "        for errs in error_lists:\n",
    "            mean_err = np.mean(errs)\n",
    "            if mean_err < best_mean:\n",
    "                best_mean = mean_err\n",
    "                best_sem = sem(errs) if len(errs) > 1 else 0.0\n",
    "        s_best_vals[s] = (best_mean, best_sem)\n",
    "    p_to_s_best[p] = s_best_vals\n",
    "\n",
    "# === Plot optimized vs fixed weight_decay (errorbars) ===\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "font_scale = 1.5\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(p_to_s_best)))\n",
    "p_to_color = {p: colors[i] for i, p in enumerate(sorted(p_to_s_best))}\n",
    "\n",
    "def shift_color(color, factor=0.85):\n",
    "    \"\"\"Darken or lighten a color by a factor.\"\"\"\n",
    "    r, g, b, a = mcolors.to_rgba(color)\n",
    "    return (min(r * factor, 1), min(g * factor, 1), min(b * factor, 1), a)\n",
    "\n",
    "# Optimized curves\n",
    "for p, s_dict in sorted(p_to_s_best.items()):\n",
    "    s_sorted = sorted(s_dict)\n",
    "    means = [s_dict[s][0] for s in s_sorted]\n",
    "    sems = [s_dict[s][1] for s in s_sorted]\n",
    "    ax.errorbar(\n",
    "        s_sorted, means, yerr=sems,\n",
    "        label=rf\"Optimized ($p$={p})\",\n",
    "        capsize=4, marker='o', linestyle='--',\n",
    "        color=p_to_color[p]\n",
    "    )\n",
    "\n",
    "# Fixed wd=1e-5 curves\n",
    "grouped_fixed_by_p = defaultdict(list)\n",
    "for exp in results_one_wd:\n",
    "    grouped_fixed_by_p[exp[\"params\"][\"p\"]].append(exp)\n",
    "\n",
    "for p, exps in sorted(grouped_fixed_by_p.items()):\n",
    "    s_to_errors = defaultdict(list)\n",
    "    for exp in exps:\n",
    "        s = exp[\"params\"][\"s\"]\n",
    "        s_to_errors[s].append(exp[\"results\"][\"reconstruction_errors\"])\n",
    "\n",
    "    s_sorted = sorted(s_to_errors)\n",
    "    means = [np.mean(sum(s_to_errors[s], [])) for s in s_sorted]\n",
    "    sems = [sem(sum(s_to_errors[s], [])) if len(s_to_errors[s]) > 1 else 0.0 for s in s_sorted]\n",
    "\n",
    "    ax.errorbar(\n",
    "        s_sorted, means, yerr=sems,\n",
    "        label=rf\"$w_d=10^{{-5}}$ ($p$={p})\",\n",
    "        capsize=4, linestyle='-',\n",
    "        color=shift_color(p_to_color[p], 0.7)\n",
    "    )\n",
    "\n",
    "# === Plot formatting ===\n",
    "ax.set_xlabel(r\"$s$\", fontsize=14 * font_scale)\n",
    "ax.set_ylabel(r\"Reconstruction Error (scaled)\", fontsize=14 * font_scale)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "ax.legend(fontsize=11 * font_scale)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda val, _: smart_formatter(val)))\n",
    "ax.tick_params(axis=\"both\", labelsize=12 * font_scale)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Results_final/reconstruction_error_vs_s_wd_scan.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# === Additional analysis and plots ===\n",
    "\n",
    "# 1. Optimal weight_decay vs s\n",
    "plot_optimal_param_vs_x(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metric=\"reconstruction_errors\",\n",
    "    parameter=\"weight_decay\",\n",
    "    group_by=\"p\",\n",
    "    save_path=\"Results_final/optimal_param_vs_s_groupp_reconstruction\",\n",
    "    font_scale=2,\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    ")\n",
    "\n",
    "# 2. Reconstruction error per row\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_error_scaled_per_row\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/reconstruction_error_scaled_per_row_vs_s_by_p\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "# 3. Other related metrics\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/reconstruction_errors_vs_s_by_p\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"pearson_corr\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/pearson_correlation_vs_s_by_p\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"spearman_corr\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/spearman_correlation_vs_s_by_p\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_error_scaled\"],\n",
    "    group_by=\"p\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/reconstruction_error_scaled_vs_s_by_p\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "# 4. Plot α vs s with reference 1/s line\n",
    "def plot_alpha_vs_s(results, s_min=0.1, s_max=1e5, save_path=\"Results_final/alpha_vs_s_group_p\"):\n",
    "    filtered = [\n",
    "        exp for exp in results\n",
    "        if s_min < exp['params'].get('s') < s_max and exp['params'].get('weight_decay') == 5e-6\n",
    "    ]\n",
    "\n",
    "    plot_metrics_vs_param(\n",
    "        results=filtered,\n",
    "        param_x=\"s\",\n",
    "        metrics=[\"alpha\"],\n",
    "        group_by=\"p\",\n",
    "        log_scale_x=True,\n",
    "        log_scale_y=True,\n",
    "        save_path=save_path,\n",
    "        sub_plot=False,\n",
    "        font_scale=2,\n",
    "        show_plot=False,\n",
    "        max_overall=True,\n",
    "        fill_between=True,\n",
    "    )\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    axes = fig.get_axes()\n",
    "\n",
    "    for ax in axes:\n",
    "        x_vals = ax.get_lines()[0].get_xdata()\n",
    "        y_vals = 1 / np.array(x_vals)\n",
    "        ax.plot(x_vals, y_vals, 'k--', label=r\"$1/s$\")\n",
    "        ax.legend(fontsize=12 * 1.5)\n",
    "        ax.set_xlabel(r\"$s$\", fontsize=12 * 1.5)\n",
    "        ax.set_ylabel(r\"$\\alpha$\", fontsize=12 * 1.5)\n",
    "\n",
    "    plt.savefig(save_path + \"_.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Call α vs s with two ranges\n",
    "plot_alpha_vs_s(results, s_min=0.1, s_max=1e5)\n",
    "plot_alpha_vs_s(results, s_min=0.5, s_max=50.1, save_path=\"Results_final/alpha_vs_s_group_p_small\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4e251",
   "metadata": {},
   "source": [
    "## Plots vs $s$ by $k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db1547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from visualization import plot_metrics_vs_param, plot_optimal_param_vs_x\n",
    "\n",
    "# === Load experiment results ===\n",
    "with open(\"Data_final/scan_K_logspaceS_wdScan_p0.2_centered_soft_label_True_2.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# === Subset: Select specific weight_decay values for visualization ===\n",
    "results_1 = [exp for exp in results if exp['params']['weight_decay'] in [1e-6, 1e-4]]\n",
    "\n",
    "# === Plot 1: Accuracy vs s, split by weight_decay, grouped by K ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_1,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"K\",\n",
    "    split_by=\"weight_decay\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/accuracy_vs_s_by_wd_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    ")\n",
    "\n",
    "# === Plot 2: Reconstruction error vs s, split by weight_decay, grouped by K ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_1,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"K\",\n",
    "    split_by=\"weight_decay\",\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    "    save_path=\"Results_final/reconstruction_vs_s_by_wd_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2\n",
    ")\n",
    "\n",
    "# === Plot 3: Best reconstruction error vs s across all wd, grouped by K ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    max_overall=True,\n",
    "    group_by=\"K\",\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=False,\n",
    "    save_path=\"Results_final/reconstruction_vs_s_groupK_optimal\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    ")\n",
    "\n",
    "# === Subset: Select specific K values for optimal param scan ===\n",
    "results_1 = [exp for exp in results if exp['params']['K'] in [1, 2, 50]]\n",
    "\n",
    "# === Plot 4: Optimal weight_decay vs s to minimize reconstruction error, grouped by K ===\n",
    "plot_optimal_param_vs_x(\n",
    "    results=results_1,\n",
    "    param_x=\"s\",\n",
    "    metric=\"reconstruction_errors\",\n",
    "    parameter=\"weight_decay\",\n",
    "    group_by=\"K\",\n",
    "    save_path=\"Results_final/optimal_param_vs_s_groupK_reconstruction\",\n",
    "    font_scale=2,\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    ")\n",
    "\n",
    "# === Plot 5: Optimal weight_decay vs s to maximize accuracy, grouped by K ===\n",
    "plot_optimal_param_vs_x(\n",
    "    results=results_1,\n",
    "    param_x=\"s\",\n",
    "    metric=\"accuracy\",\n",
    "    parameter=\"weight_decay\",\n",
    "    group_by=\"K\",\n",
    "    save_path=\"Results_final/optimal_param_vs_s_groupK_accuracy\",\n",
    "    font_scale=2,\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    ")\n",
    "\n",
    "# === Subset: Focus on s ∈ [0.1, 100] and weight_decay = 1e-5 ===\n",
    "results_3 = [\n",
    "    exp for exp in results\n",
    "    if 0.1 <= exp['params']['s'] <= 100 and exp['params']['weight_decay'] == 1e-5\n",
    "]\n",
    "\n",
    "# === Plot 6: Accuracy vs s (filtered), grouped by K ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_3,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    max_overall=True,\n",
    "    group_by=\"K\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/accuracy_vs_s_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    ")\n",
    "\n",
    "# === Plot 7: Reconstruction error vs s (filtered), grouped by K ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_3,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    max_overall=True,\n",
    "    group_by=\"K\",\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=True,\n",
    "    save_path=\"Results_final/reconstruction_vs_s_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae6aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.stats import sem\n",
    "from matplotlib import colors as mcolors\n",
    "from visualization import plot_metrics_vs_param, smart_formatter\n",
    "\n",
    "# === Load experiment results ===\n",
    "file_path = \"Data_final/scan_K_logspaceS_wdScan_p0.2_centered_soft_label_True_2.pkl\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# === Filter: select experiments with p = 0.2 and K ∈ {1, 10, 50}, s ∈ [0.01, 100] ===\n",
    "results_p_02 = [\n",
    "    exp for exp in results\n",
    "    if exp[\"params\"][\"p\"] == 0.2\n",
    "    and exp[\"params\"][\"K\"] in [1, 10, 50]\n",
    "    and 0.01 <= exp[\"params\"][\"s\"] <= 100\n",
    "]\n",
    "\n",
    "# === Separate two groups: fixed weight decay vs optimized ===\n",
    "results_fixed_wd = [copy.deepcopy(exp) for exp in results_p_02 if exp[\"params\"][\"weight_decay\"] == 1e-5]\n",
    "results_optimized = [copy.deepcopy(exp) for exp in results_p_02]\n",
    "\n",
    "# === Rename groups for legend labels ===\n",
    "for exp in results_fixed_wd:\n",
    "    exp[\"params\"][\"wd\"] = \"$10^{-5}$\"\n",
    "for exp in results_optimized:\n",
    "    exp[\"params\"][\"wd\"] = \"Optimized\"\n",
    "\n",
    "# === Combine both sets for alternative plot if needed ===\n",
    "results_combined = results_fixed_wd + results_optimized\n",
    "\n",
    "# Optional:\n",
    "# plot_metrics_vs_param(\n",
    "#     results=results_combined,\n",
    "#     param_x=\"s\",\n",
    "#     metrics=[\"reconstruction_errors\"],\n",
    "#     max_overall=True,\n",
    "#     group_by=[\"wd\", \"K\"],\n",
    "#     log_scale_x=True,\n",
    "#     log_scale_y=True,\n",
    "#     save_path=\"Results_final/reconstruction_error_vs_s_wd_by_K\",\n",
    "#     font_scale=1.5,\n",
    "# )\n",
    "\n",
    "# === STEP 1: Group optimized experiments by K ===\n",
    "grouped_by_K = defaultdict(list)\n",
    "for exp in results_optimized:\n",
    "    grouped_by_K[exp[\"params\"][\"K\"]].append(exp)\n",
    "\n",
    "# === STEP 2: Compute best mean ± SEM per s for each K ===\n",
    "K_to_s_best = {}\n",
    "for K, exps in grouped_by_K.items():\n",
    "    s_to_errors = defaultdict(list)\n",
    "    for exp in exps:\n",
    "        s = exp[\"params\"][\"s\"]\n",
    "        s_to_errors[s].append(exp[\"results\"][\"reconstruction_errors\"])\n",
    "\n",
    "    s_best_vals = {}\n",
    "    for s, error_lists in s_to_errors.items():\n",
    "        best_mean = float(\"inf\")\n",
    "        best_sem = None\n",
    "        for errs in error_lists:\n",
    "            mean_err = np.mean(errs)\n",
    "            if mean_err < best_mean:\n",
    "                best_mean = mean_err\n",
    "                best_sem = sem(errs) if len(errs) > 1 else 0.0\n",
    "        s_best_vals[s] = (best_mean, best_sem)\n",
    "    K_to_s_best[K] = s_best_vals\n",
    "\n",
    "# === STEP 3: Plot curves (Optimized vs Fixed wd) with error bars ===\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "font_scale = 1.5\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(K_to_s_best)))\n",
    "K_to_color = {K: colors[i] for i, K in enumerate(sorted(K_to_s_best))}\n",
    "\n",
    "def shift_color(color, factor=0.85):\n",
    "    \"\"\"Darken or lighten a given RGBA color.\"\"\"\n",
    "    r, g, b, a = mcolors.to_rgba(color)\n",
    "    return (min(r * factor, 1), min(g * factor, 1), min(b * factor, 1), a)\n",
    "\n",
    "# === Optimized curves ===\n",
    "for K, s_dict in sorted(K_to_s_best.items()):\n",
    "    s_sorted = sorted(s_dict)\n",
    "    means = [s_dict[s][0] for s in s_sorted]\n",
    "    sems = [s_dict[s][1] for s in s_sorted]\n",
    "    base_color = K_to_color[K]\n",
    "    ax.errorbar(\n",
    "        s_sorted, means, yerr=sems,\n",
    "        label=f\"Optimized (K={K})\",\n",
    "        capsize=4,\n",
    "        marker='o',\n",
    "        linestyle='--',\n",
    "        color=base_color\n",
    "    )\n",
    "\n",
    "# === Fixed wd = 1e-5 curves ===\n",
    "grouped_fixed_by_K = defaultdict(list)\n",
    "for exp in results_fixed_wd:\n",
    "    grouped_fixed_by_K[exp[\"params\"][\"K\"]].append(exp)\n",
    "\n",
    "for K, exps in sorted(grouped_fixed_by_K.items()):\n",
    "    s_to_errors = defaultdict(list)\n",
    "    for exp in exps:\n",
    "        s = exp[\"params\"][\"s\"]\n",
    "        s_to_errors[s].append(exp[\"results\"][\"reconstruction_errors\"])\n",
    "\n",
    "    s_sorted = sorted(s_to_errors)\n",
    "    means = [np.mean(sum(s_to_errors[s], [])) for s in s_sorted]\n",
    "    sems = [sem(sum(s_to_errors[s], [])) if len(s_to_errors[s]) > 1 else 0.0 for s in s_sorted]\n",
    "    shifted_color = shift_color(K_to_color[K], 0.7)\n",
    "\n",
    "    ax.errorbar(\n",
    "        s_sorted, means, yerr=sems,\n",
    "        label=rf\"$w_d=10^{{-5}}$ (K={K})\",\n",
    "        capsize=4,\n",
    "        linestyle='-',\n",
    "        color=shifted_color\n",
    "    )\n",
    "\n",
    "# === Format axes, grid, and legend ===\n",
    "ax.set_xlabel(r\"$s$\", fontsize=14 * font_scale)\n",
    "ax.set_ylabel(r\"Reconstruction Error (scaled)\", fontsize=14 * font_scale)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "ax.legend(fontsize=11 * font_scale)\n",
    "\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda val, _: smart_formatter(val)))\n",
    "ax.tick_params(axis=\"both\", labelsize=12 * font_scale)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Results_final/reconstruction_error_vs_s_wd_by_K.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from visualization import plot_metrics_vs_param\n",
    "from visualization import smart_formatter\n",
    "\n",
    "# === Load experiment results ===\n",
    "file_path = \"Data_final/scan_K_logspaceS_wdScan_p0.2_centered_soft_label_True_2.pkl\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# === Plot: reconstruction_error_scaled vs s (split by weight_decay, grouped by K) ===\n",
    "results_2 = [exp for exp in results if exp['params']['weight_decay'] in [1e-6, 1e-4]]\n",
    "plot_metrics_vs_param(\n",
    "    results=results_2,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_error_scaled\"],\n",
    "    group_by=\"K\",\n",
    "    split_by=\"weight_decay\",\n",
    "    max_overall=True,\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=False,\n",
    "    save_path=\"Results_final/reconstruction_scaled_vs_s_by_wd_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2\n",
    ")\n",
    "\n",
    "# === Plot: reconstruction_error_scaled vs s (grouped by K, across all weight_decay) ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_error_scaled\"],\n",
    "    max_overall=True,\n",
    "    group_by=\"K\",\n",
    "    log_scale_x=True,\n",
    "    log_scale_y=False,\n",
    "    save_path=\"Results_final/reconstruction_scaled_vs_s_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    ")\n",
    "\n",
    "# === Define reusable function to plot alpha vs s and overlay 1/s ===\n",
    "def plot_alpha_vs_s(results, s_min=-1, s_max=1e5, save_path=\"Results_final/alpha_vs_s_groupK\"):\n",
    "    filtered = [\n",
    "        exp for exp in results\n",
    "        if s_min < exp['params'].get('s') < s_max and exp['params'].get('weight_decay') in [1e-5, 5e-5, 1e-4, 5e-4]\n",
    "    ]\n",
    "\n",
    "    plot_metrics_vs_param(\n",
    "        results=filtered,\n",
    "        param_x=\"s\",\n",
    "        metrics=[\"alpha\"],\n",
    "        group_by=\"K\",\n",
    "        log_scale_x=True,\n",
    "        log_scale_y=True,\n",
    "        split_by=\"weight_decay\",\n",
    "        save_path=save_path,\n",
    "        sub_plot=True,\n",
    "        font_scale=2,\n",
    "        show_plot=False,\n",
    "    )\n",
    "\n",
    "    # Overlay 1/s reference line on each subplot\n",
    "    fig = plt.gcf()\n",
    "    axes = fig.get_axes()\n",
    "    for ax in axes:\n",
    "        x_vals = ax.get_lines()[0].get_xdata()\n",
    "        y_vals = 1 / np.array(x_vals)\n",
    "        ax.plot(x_vals, y_vals, 'k--', label=r\"$1/s$\")\n",
    "        ax.legend(fontsize=12 * 2)\n",
    "    plt.savefig(save_path + \".png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# === Call alpha vs s function at different scales ===\n",
    "plot_alpha_vs_s(results, s_min=0.15, s_max=1e5)\n",
    "plot_alpha_vs_s(results, s_min=0.15, s_max=10.1, save_path=\"Results_final/alpha_vs_s_groupK_small\")\n",
    "\n",
    "# === Correlation metrics filtering ===\n",
    "results_2 = [\n",
    "    exp for exp in results\n",
    "    if 0.009 < exp['params'].get('s') < 10 and exp['params'].get('weight_decay') in [1e-5, 5e-5, 1e-4, 5e-4]\n",
    "]\n",
    "results_3 = [exp for exp in results if 0.009 < exp['params'].get('s') < 10]\n",
    "\n",
    "# === Plot: Pearson correlation vs s ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_2,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"pearson_corr\"],\n",
    "    group_by=\"K\",\n",
    "    split_by=\"weight_decay\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/pearson_corr_vs_s_by_wd_groupK\",\n",
    "    sub_plot=True,\n",
    "    max_overall=True,\n",
    "    font_scale=2,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "plot_metrics_vs_param(\n",
    "    results=results_3,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"pearson_corr\"],\n",
    "    group_by=\"K\",\n",
    "    max_overall=True,\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/pearson_corr_vs_s_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "# === Plot: Spearman correlation vs s ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_2,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"spearman_corr\"],\n",
    "    group_by=\"K\",\n",
    "    split_by=\"weight_decay\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/spearman_corr_vs_s_by_wd_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    "    max_overall=True,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "plot_metrics_vs_param(\n",
    "    results=results_3,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"spearman_corr\"],\n",
    "    group_by=\"K\",\n",
    "    max_overall=True,\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/spearman_corr_vs_s_groupK\",\n",
    "    sub_plot=True,\n",
    "    font_scale=2,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "# === Plot: Row-wise scaled reconstruction error vs s (grouped by K) ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_error_scaled_per_row\"],\n",
    "    group_by=\"K\",\n",
    "    log_scale_x=True,\n",
    "    save_path=\"Results_final/reconstruction_error_scaled_per_row_vs_s_groupK\",\n",
    "    max_overall=True,\n",
    "    font_scale=1.5,\n",
    "    # ylim=(0, 0.4)  # Uncomment to set custom y-axis limits\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe6f938",
   "metadata": {},
   "source": [
    "# Plots explaining the difference in Reconstruction Error Scaled per Row and the Pearson coefficient \n",
    "(for high $s$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb30c146",
   "metadata": {},
   "source": [
    "## Comparison of the distribution of the values per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "\n",
    "# === Load experiment results ===\n",
    "with open(\"Data_final/scan_K_logspaceS_wdScan_p0.2_centered_soft_label_True_2.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "def plot_sampled_comparison_aligned(UVT_row, X_row, title=None, save_path=None, font_scale=1.5, real_index=None):\n",
    "    \"\"\"\n",
    "    Plot a single row from UVT and X, sorted by X values, using dual y-axes.\n",
    "\n",
    "    Args:\n",
    "        UVT_row (array-like): Predicted values\n",
    "        X_row (array-like): Ground-truth values\n",
    "        title (str): Optional title\n",
    "        save_path (str): Optional save path for the figure\n",
    "        font_scale (float): Scaling factor for font sizes\n",
    "        real_index (int): Optional, for reference\n",
    "    \"\"\"\n",
    "    UVT_row = np.array(UVT_row)\n",
    "    X_row = np.array(X_row)\n",
    "    sort_idx = np.argsort(X_row)\n",
    "    x = np.arange(len(X_row))\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    color1 = 'tab:red'\n",
    "    ax1.set_ylabel(r'$UV^\\top$', color=color1, fontsize=12*font_scale)\n",
    "    ax1.plot(x, UVT_row[sort_idx], color=color1, label=r'$UV^\\top$')\n",
    "    ax1.tick_params(axis='y', labelcolor=color1, labelsize=12*font_scale)\n",
    "    ax1.tick_params(axis='x', labelsize=12*font_scale)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = 'tab:blue'\n",
    "    ax2.set_ylabel(r'$X$', color=color2, fontsize=12*font_scale)\n",
    "    ax2.plot(x, X_row[sort_idx], color=color2, linestyle='--', label=r'$X$')\n",
    "    ax2.tick_params(axis='y', labelcolor=color2, labelsize=12*font_scale)\n",
    "\n",
    "    fig.suptitle(title if title else \"$UV^\\\\top$ vs $X$ (sorted)\", fontsize=14*font_scale)\n",
    "    ax1.set_xlabel(\"Sorted Index\", fontsize=12*font_scale)\n",
    "    fig.tight_layout()\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.5, which='both')\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def find_closest_index_by_s(results, s_target):\n",
    "    \"\"\"\n",
    "    Find the index of the experiment with s closest to s_target.\n",
    "\n",
    "    Args:\n",
    "        results (list): List of experiment dictionaries\n",
    "        s_target (float): Target s value\n",
    "\n",
    "    Returns:\n",
    "        int: Index of the closest experiment\n",
    "    \"\"\"\n",
    "    min_dist = float('inf')\n",
    "    closest_idx = -1\n",
    "    for i, res in enumerate(results):\n",
    "        s_val = res[\"params\"].get(\"s\")\n",
    "        if s_val is not None:\n",
    "            dist = abs(s_val - s_target)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_idx = i\n",
    "    return closest_idx\n",
    "\n",
    "# === Plot comparison for a few s values ===\n",
    "s_targets = [0.1, 5, 100]\n",
    "i_indices = [find_closest_index_by_s(results, s_target) for s_target in s_targets]\n",
    "print(f\"Closest indices found for s={s_targets}: {i_indices}\")\n",
    "\n",
    "rep = [0]  # Repetition indices\n",
    "for k, i in enumerate(i_indices):\n",
    "    for reps in rep:\n",
    "        sampled_UVT_rows = results[i][\"results\"][\"sampled_UVT_rows\"][reps]\n",
    "        sampled_X_rows = results[i][\"results\"][\"sampled_X_rows\"][reps]\n",
    "        row_id = choice(range(len(sampled_UVT_rows)))\n",
    "\n",
    "        UVT_row = sampled_UVT_rows[row_id]\n",
    "        X_row = sampled_X_rows[row_id]\n",
    "\n",
    "        plot_sampled_comparison_aligned(\n",
    "            UVT_row,\n",
    "            X_row,\n",
    "            title=f\"s = {s_targets[k]}\",\n",
    "            real_index=i,\n",
    "            save_path=f\"Results_final/sample_comparison_s_{s_targets[k]}.png\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c695cf64",
   "metadata": {},
   "source": [
    "## Histrogram of the distribution of the $\\alpha_u$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618df6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === Load results ===\n",
    "file_path_1 = \"Data_final/scan_K_logspaceS_wdScan_p0.2_centered_soft_label_True_2.pkl\"\n",
    "with open(file_path_1, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# Filter experiments for K = 1\n",
    "results = [exp for exp in results if exp['params'].get('K') == 1]\n",
    "\n",
    "# Target values of s for which we want histograms\n",
    "target_s_values = [0.1, 5, 10, 100]\n",
    "\n",
    "# Find experiments with closest s to each target\n",
    "selected_experiments = []\n",
    "selected_s_values = []\n",
    "\n",
    "for s_target in target_s_values:\n",
    "    closest_exp = min(results, key=lambda exp: abs(exp[\"params\"][\"s\"] - s_target))\n",
    "    s_val = closest_exp[\"params\"][\"s\"]\n",
    "    if s_val not in selected_s_values:  # Avoid duplicates\n",
    "        selected_experiments.append(closest_exp)\n",
    "        selected_s_values.append(s_val)\n",
    "\n",
    "print(\"Selected s values:\", selected_s_values)\n",
    "\n",
    "# === Create 2x2 subplot layout ===\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, s_val in enumerate(selected_s_values):\n",
    "    # Get corresponding experiment and per-row slopes\n",
    "    exp = next(exp for exp in results if exp[\"params\"][\"s\"] == s_val)\n",
    "    slopes = exp[\"results\"][\"alpha_per_row\"]\n",
    "    all_slopes = [v for sublist in slopes for v in sublist] if isinstance(slopes[0], list) else slopes\n",
    "\n",
    "    # Compute statistics\n",
    "    the_mean = np.mean(all_slopes)\n",
    "    alpha_total = exp[\"results\"][\"alpha\"]\n",
    "    the_alpha = np.mean(alpha_total)\n",
    "\n",
    "    # === Plot histogram of per-row slopes with vertical lines ===\n",
    "    font_scale = 0.7\n",
    "    ax = axes[idx]\n",
    "    ax.hist(all_slopes, bins=50, alpha=0.7, color='blue')\n",
    "    ax.axvline(the_mean, color='red', linestyle='--', label=fr\"Mean of slopes = {the_mean:.5f}\")\n",
    "    ax.axvline(the_alpha, color='black', linestyle='--', label=fr\"Global Alpha = {the_alpha:.5f}\")\n",
    "    ax.set_title(rf\"$s = {s_val}$\", fontsize=22 * font_scale)\n",
    "    ax.set_xlabel(r\"$\\alpha_u$\", fontsize=25 * font_scale)\n",
    "    ax.set_ylabel(\"Count\", fontsize=20 * font_scale)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax.tick_params(axis='both', labelsize=12 * 2 * font_scale)\n",
    "    ax.legend(fontsize=20 * font_scale)\n",
    "\n",
    "# Final layout and saving\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(\"Results_final/Slopes_histogram_4_different_s.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4717210",
   "metadata": {},
   "source": [
    "## Effect of the outlier and of the noise on the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aed646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_metrics(x, y):\n",
    "    \"\"\"\n",
    "    Computes the Pearson correlation and normalized reconstruction error between vectors x and y.\n",
    "    \"\"\"\n",
    "    pearson, _ = pearsonr(x, y)\n",
    "    reconstruction_error = np.linalg.norm(x - y) / np.linalg.norm(x)\n",
    "    return pearson, reconstruction_error\n",
    "\n",
    "def plot_outlier_impact(font_scale=1.5):\n",
    "    \"\"\"\n",
    "    Plots how increasing the magnitude of a single outlier affects both Pearson correlation\n",
    "    and normalized reconstruction error.\n",
    "    \"\"\"\n",
    "    # === Set font sizes globally ===\n",
    "    plt.rcParams.update({\n",
    "        'axes.titlesize': 14 * font_scale,\n",
    "        'axes.labelsize': 12 * font_scale,\n",
    "        'xtick.labelsize': 10 * font_scale,\n",
    "        'ytick.labelsize': 10 * font_scale,\n",
    "        'legend.fontsize': 10 * font_scale,\n",
    "        'figure.titlesize': 15 * font_scale\n",
    "    })\n",
    "\n",
    "    # === Generate reference vectors ===\n",
    "    np.random.seed(0)\n",
    "    x = np.linspace(0, 10, 100)\n",
    "    y_base = x + np.random.normal(0, 0.5, size=x.shape)\n",
    "\n",
    "    # === Define outlier magnitudes ===\n",
    "    outlier_magnitudes = np.linspace(0, 100, 200)\n",
    "    pearsons = []\n",
    "    errors = []\n",
    "\n",
    "    # === Evaluate metrics as the outlier grows ===\n",
    "    for magnitude in outlier_magnitudes:\n",
    "        y = y_base.copy()\n",
    "        y[-1] += magnitude  # Inject outlier\n",
    "        p, err = compute_metrics(x, y)\n",
    "        pearsons.append(p)\n",
    "        errors.append(err)\n",
    "\n",
    "    # === Create the plot ===\n",
    "    fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    color1 = 'tab:blue'\n",
    "    ax1.set_xlabel(\"Outlier magnitude\")\n",
    "    ax1.set_ylabel(\"Pearson correlation\", color=color1)\n",
    "    ax1.plot(outlier_magnitudes, pearsons, color=color1, label=\"Pearson\")\n",
    "    ax1.tick_params(axis='y', labelcolor=color1)\n",
    "    ax1.set_ylim(0.0, 1.01)\n",
    "    ax1.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color2 = 'tab:red'\n",
    "    ax2.set_ylabel(\"Reconstruction error\", color=color2)\n",
    "    ax2.plot(outlier_magnitudes, errors, color=color2, linestyle='--', label=\"Reconstruction Error\")\n",
    "    ax2.tick_params(axis='y', labelcolor=color2)\n",
    "    ax2.set_ylim(0, 1.05)\n",
    "    ax2.invert_yaxis()  # Optional: inverted for visual emphasis\n",
    "\n",
    "    fig.suptitle(\"Effect of Outlier Magnitude on Pearson and Reconstruction Error\")\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"Results_final/outlier_impact_pearson_reconstruction.png\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "# === Run the plot ===\n",
    "plot_outlier_impact()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd36c5e",
   "metadata": {},
   "source": [
    "# Plots for $p\\cdot k=const$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e8503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_metrics_vs_param\n",
    "import pickle\n",
    "\n",
    "# === Load results ===\n",
    "file_path = \"Data_final/scan_pK_constant_Final_s_wd_sweep.pkl\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    all_results = pickle.load(f)\n",
    "\n",
    "# === Add product pxK to params for grouping ===\n",
    "for exp in all_results:\n",
    "    p = exp['params']['p']\n",
    "    K = exp['params']['K']\n",
    "    exp['params']['pxK'] = round(p * K, 4)\n",
    "\n",
    "# === Filter experiments by value of s ===\n",
    "results_s1 = [exp for exp in all_results if exp['params'].get('s') == 1]\n",
    "results_s3 = [exp for exp in all_results if exp['params'].get('s') == 3]\n",
    "results_s5 = [exp for exp in all_results if exp['params'].get('s') == 5]\n",
    "results_s8 = [exp for exp in all_results if exp['params'].get('s') == 8]\n",
    "\n",
    "# === Plot for s = 1 ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s1,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/accuracy_vs_K_grouped_by_pxK_s1\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5,\n",
    "    GT_plot=False\n",
    ")\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s1,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/reconstruction_errors_vs_K_grouped_by_pxK_s1\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Plot for s = 3 ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s3,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/accuracy_vs_K_grouped_by_pxK_s3\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5,\n",
    "    GT_plot=False\n",
    ")\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s3,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/reconstruction_errors_vs_K_grouped_by_pxK_s3\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Plot for s = 5 ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s5,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/accuracy_vs_K_grouped_by_pxK_s5\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5,\n",
    "    GT_plot=False\n",
    ")\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s5,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/reconstruction_errors_vs_K_grouped_by_pxK_s5\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s5,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"reconstruction_error_scaled_per_row\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/reconstruction_errors_scaled_per_row_vs_K_grouped_by_pxK_s5\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Plot for s = 8 ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s8,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/accuracy_vs_K_grouped_by_pxK_s8\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5,\n",
    "    GT_plot=False\n",
    ")\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s8,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/reconstruction_errors_vs_K_grouped_by_pxK_s8\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "plot_metrics_vs_param(\n",
    "    results=results_s8,\n",
    "    param_x=\"K\",\n",
    "    metrics=[\"reconstruction_error_scaled_per_row\"],\n",
    "    group_by=\"pxK\",\n",
    "    save_path=\"Results_final/reconstruction_errors_scaled_per_row_vs_K_grouped_by_pxK_s8\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5\n",
    ")\n",
    "\n",
    "# === Example of other metrics you may want to plot ===\n",
    "# plot_metrics_vs_param(\n",
    "#     results=results_s8,\n",
    "#     param_x=\"K\",\n",
    "#     metrics=[\"pearson_corr\"],\n",
    "#     group_by=\"pxK\",\n",
    "#     save_path=\"Results_final/pearson_corr_vs_K_grouped_by_pxK_s8\",\n",
    "#     max_overall=True,\n",
    "#     grid=True,\n",
    "#     sub_plot=False,\n",
    "#     show_plot=True,\n",
    "#     font_scale=1.5\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e2fbe",
   "metadata": {},
   "source": [
    "# Plots vs $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24760f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import plot_metrics_vs_param\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# === Load results ===\n",
    "filename = \"Data_final/scan_pK_Final.pkl\"\n",
    "with open(filename, \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# === Plot 1: Accuracy vs p, grouped by K (all results) ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"p\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"K\",\n",
    "    title=\"Accuracy vs p grouped by K\",\n",
    "    save_path=\"Results_final/accuracy_vs_p_grouped_by_K\",\n",
    "    log_scale_x=True,\n",
    "    grid=True,\n",
    "    max_overall=True,\n",
    "    sub_plot=False,\n",
    "    show_plot=True,\n",
    "    font_scale=1.5,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "# === Filter for selected K values and p range ===\n",
    "results_k = [\n",
    "    exp for exp in results \n",
    "    if exp['params']['K'] in [1, 3, 10] and 0.05 <= exp['params']['p'] <= 0.5\n",
    "]\n",
    "\n",
    "# === Plot 2: Accuracy vs p, for K = 1, 3, 10 ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_k,\n",
    "    param_x=\"p\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"K\",\n",
    "    title=\"Accuracy vs p (K = 1, 3, 10)\",\n",
    "    log_scale_x=True,\n",
    "    grid=True,\n",
    "    max_overall=True,\n",
    "    sub_plot=True,\n",
    "    show_plot=False,\n",
    "    ylim=(0.49, 0.85),\n",
    "    font_scale=1.3,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "# === Add legend and save manually ===\n",
    "plt.legend(\n",
    "    loc=\"lower right\",\n",
    "    fontsize=12 * 1.3,\n",
    "    title_fontsize=12 * 1.3,\n",
    ")\n",
    "plt.savefig(\"Results_final/accuracy_vs_p_K1_to_10.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# === Plot 3: Reconstruction Error vs p, for K = 1, 3, 10 ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_k,\n",
    "    param_x=\"p\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"K\",\n",
    "    title=\"Reconstruction Error vs p (K = 1, 3, 10)\",\n",
    "    save_path=\"Results_final/reconstruction_errors_vs_p_grouped_by_K\",\n",
    "    log_scale_x=True,\n",
    "    grid=True,\n",
    "    max_overall=True,\n",
    "    sub_plot=True,\n",
    "    show_plot=True,\n",
    "    font_scale=1.3,\n",
    "    fill_between=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f78e26",
   "metadata": {},
   "source": [
    "## Plots for $p\\cdot s = const$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from visualization import plot_metrics_vs_param\n",
    "\n",
    "# === Load results from both experiment files ===\n",
    "with open(\"Data_final/scan_ps_constant_Final_2.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "with open(\"Data_final/scan_ps_constant_Final.pkl\", \"rb\") as f:\n",
    "    results_2 = pickle.load(f)\n",
    "\n",
    "# Merge both result lists\n",
    "results = results + results_2\n",
    "print(\"✅ Results loaded successfully!\")\n",
    "\n",
    "# === Preprocess: compute p*s and filter relevant experiments ===\n",
    "for exp in results:\n",
    "    p = exp['params']['p']\n",
    "    s = exp['params']['s']\n",
    "    exp['params']['p*s'] = round(p * s, 2)  # Add p*s product to params\n",
    "\n",
    "# Filter to retain only experiments with specific p*s values and s in [1, 9]\n",
    "target_pxs = [0.9, 0.7, 0.6, 0.55, 0.5, 0.35, 0.25]\n",
    "results = [\n",
    "    exp for exp in results \n",
    "    if exp['params']['p*s'] in target_pxs and 1 <= exp['params']['s'] <= 9\n",
    "]\n",
    "\n",
    "# === Plot 1: Accuracy vs s, grouped by p*s ===\n",
    "plot_metrics_vs_param(\n",
    "    results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"accuracy\"],\n",
    "    group_by=\"p*s\",\n",
    "    save_path=\"Results_final/accuracy_vs_s_grouped_by_pxs_2\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    font_scale=1.5,\n",
    "    show_plot=False,\n",
    "    fill_between=True,\n",
    ")\n",
    "plt.legend(loc='upper left', fontsize=12 * 1.3)\n",
    "plt.xlim(1, 9.5)\n",
    "plt.savefig(\"Results_3/accuracy_vs_s_grouped_by_pxs_2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# === Plot 2: Reconstruction Error vs s, grouped by p*s ===\n",
    "plot_metrics_vs_param(\n",
    "    results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_errors\"],\n",
    "    group_by=\"p*s\",\n",
    "    save_path=\"Results_final/reconstruction_error_vs_s_grouped_by_pxs_2\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    font_scale=1.5,\n",
    "    fill_between=True,\n",
    ")\n",
    "\n",
    "# === Plot 3: Scaled Reconstruction Error per row vs s, grouped by p*s ===\n",
    "plot_metrics_vs_param(\n",
    "    results,\n",
    "    param_x=\"s\",\n",
    "    metrics=[\"reconstruction_error_scaled_per_row\"],\n",
    "    group_by=\"p*s\",\n",
    "    save_path=\"Results_final/reconstruction_error_scaled_per_row_vs_s_grouped_by_pxs_2\",\n",
    "    max_overall=True,\n",
    "    grid=True,\n",
    "    sub_plot=False,\n",
    "    font_scale=1.5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daacf6ee",
   "metadata": {},
   "source": [
    "# Plots for $p$ vs $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad84156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from visualization import plot_all_heatmaps\n",
    "\n",
    "# === Load experiment results ===\n",
    "with open(\"./Data_final/p_d_1.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "print(\"✅ Results successfully loaded from './Data_final/p_d_1.pkl'.\")\n",
    "\n",
    "# === Plot heatmap: Accuracy as a function of (p, d) ===\n",
    "plot_all_heatmaps(\n",
    "    results,\n",
    "    save_path=\"./Results_final/p_d_accuracy_heatmap\",\n",
    "    result_metric=\"accuracy\",\n",
    "    param_x=\"p\",\n",
    "    param_y=\"d\",\n",
    "    fig_size=(10, 5),\n",
    "    font_scale=1.3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ddf13",
   "metadata": {},
   "source": [
    "# Plots for Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604ac1b",
   "metadata": {},
   "source": [
    "## Plots for strategies vs $s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from visualization import plot_metrics_vs_param\n",
    "\n",
    "# === Define all strategies to include ===\n",
    "strategies = [\"random\", \"proximity\", \"margin\", \"variance\", \"popularity\", \"top_k\", \"svd\"]\n",
    "\n",
    "# === Load all experiment results from strategy scans ===\n",
    "results = []\n",
    "for strategy in strategies:\n",
    "    file_path = f\"Data_strategies/run_vs_s_K1_{strategy}_wd_sweep.pkl\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        results.extend(pickle.load(f))\n",
    "\n",
    "# === Define strategy groups for comparison ===\n",
    "group_1 = {\"random\", \"proximity\", \"svd\", \"margin\", \"top_k\"}\n",
    "group_2 = {\"random\", \"popularity\"}\n",
    "\n",
    "# === Define the metrics to be plotted ===\n",
    "metrics = [\n",
    "    \"gt_accuracy\",\n",
    "    \"accuracy\",\n",
    "    \"reconstruction_error_scaled\",\n",
    "    \"pearson_corr\",\n",
    "    \"spearman_corr\"\n",
    "]\n",
    "\n",
    "# === Loop over all metrics and generate plots per group ===\n",
    "for metric in metrics:\n",
    "\n",
    "    # === Filter results for group 1 ===\n",
    "    results_group1 = [\n",
    "        r for r in results\n",
    "        if r[\"params\"][\"strategy\"] in group_1 and\n",
    "           (r[\"params\"].get(\"weight_decay\") == 1e-5 if \"alpha\" in metric else True)\n",
    "    ]\n",
    "    if metric == \"reconstruction_errors\":\n",
    "        results_group1 = [r for r in results_group1 if r[\"params\"].get(\"s\", 0) > 0.2]\n",
    "\n",
    "    # === Plot for group 1 ===\n",
    "    plot_metrics_vs_param(\n",
    "        results=results_group1,\n",
    "        param_x=\"s\",\n",
    "        metrics=[metric],\n",
    "        group_by=\"strategy\",\n",
    "        log_scale_x=True,\n",
    "        log_scale_y=(\"loss\" in metric or \"alpha\" in metric),\n",
    "        sub_plot=True,\n",
    "        font_scale=1.6,\n",
    "        max_overall=True,\n",
    "        save_path=f\"Results_strategies/{metric}_vs_s_group_strategy_set1\",\n",
    "        use_color_gradient=False,\n",
    "        GT_plot=False,\n",
    "        fill_between=True,\n",
    "    )\n",
    "\n",
    "    # === Filter results for group 2 ===\n",
    "    results_group2 = [\n",
    "        r for r in results\n",
    "        if r[\"params\"][\"strategy\"] in group_2 and\n",
    "           (r[\"params\"].get(\"weight_decay\") == 1e-5 if \"alpha\" in metric else True)\n",
    "    ]\n",
    "    if metric == \"reconstruction_errors\":\n",
    "        results_group2 = [r for r in results_group2 if r[\"params\"].get(\"s\", 0) > 0.2]\n",
    "\n",
    "    # === Plot for group 2 ===\n",
    "    plot_metrics_vs_param(\n",
    "        results=results_group2,\n",
    "        param_x=\"s\",\n",
    "        metrics=[metric],\n",
    "        group_by=\"strategy\",\n",
    "        log_scale_x=True,\n",
    "        log_scale_y=(\"loss\" in metric or \"alpha\" in metric),\n",
    "        sub_plot=True,\n",
    "        font_scale=1.6,\n",
    "        max_overall=True,\n",
    "        save_path=f\"Results_strategies/{metric}_vs_s_group_strategy_set2\",\n",
    "        use_color_gradient=False,\n",
    "        GT_plot=False,\n",
    "        fill_between=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75eace4",
   "metadata": {},
   "source": [
    "## Plots for strategies vs $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e21a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from visualization import plot_metrics_vs_param\n",
    "\n",
    "# === Load results for scans over p ===\n",
    "strategies = [\"random\", \"proximity\", \"margin\", \"variance\", \"popularity\", \"top_k\", \"svd\"]\n",
    "results_p = []\n",
    "\n",
    "# Load both versions of each strategy's run (original and _2)\n",
    "for strategy in strategies:\n",
    "    with open(f\"Data_strategies/run_vs_p_{strategy}.pkl\", \"rb\") as f:\n",
    "        results_p.extend(pickle.load(f))\n",
    "    with open(f\"Data_strategies/run_vs_p_{strategy}_2.pkl\", \"rb\") as f:\n",
    "        results_p.extend(pickle.load(f))\n",
    "\n",
    "# === Define strategy groups for comparison ===\n",
    "group_1 = {\"random\", \"proximity\", \"svd\"}\n",
    "group_2 = {\"random\", \"popularity\"}\n",
    "\n",
    "# === Define metrics to plot ===\n",
    "metrics = [\"accuracy\", \"reconstruction_error_scaled\", \"pearson_corr\", \"spearman_corr\"]\n",
    "\n",
    "# === Generate plots for each metric and strategy group ===\n",
    "for metric in metrics:\n",
    "    # Filter results by strategy group\n",
    "    results_group1 = [r for r in results_p if r[\"params\"][\"strategy\"] in group_1]\n",
    "    results_group2 = [r for r in results_p if r[\"params\"][\"strategy\"] in group_2]\n",
    "\n",
    "    # Plot for group 1\n",
    "    plot_metrics_vs_param(\n",
    "        results=results_group1,\n",
    "        param_x=\"p\",\n",
    "        metrics=[metric],\n",
    "        group_by=\"strategy\",\n",
    "        log_scale_x=True,\n",
    "        log_scale_y=(\"loss\" in metric or \"alpha\" in metric),\n",
    "        sub_plot=True,\n",
    "        font_scale=1.6,\n",
    "        max_overall=True,\n",
    "        save_path=f\"Results_strategies/{metric}_vs_p_group_strategy_set1\",\n",
    "        use_color_gradient=False,\n",
    "        GT_plot=False,\n",
    "        fill_between=True,\n",
    "    )\n",
    "\n",
    "    # Plot for group 2\n",
    "    plot_metrics_vs_param(\n",
    "        results=results_group2,\n",
    "        param_x=\"p\",\n",
    "        metrics=[metric],\n",
    "        group_by=\"strategy\",\n",
    "        log_scale_x=True,\n",
    "        log_scale_y=(\"loss\" in metric or \"alpha\" in metric),\n",
    "        sub_plot=True,\n",
    "        font_scale=1.6,\n",
    "        max_overall=True,\n",
    "        save_path=f\"Results_strategies/{metric}_vs_p_group_strategy_set2\",\n",
    "        use_color_gradient=False,\n",
    "        GT_plot=False,\n",
    "        fill_between=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5946e",
   "metadata": {},
   "source": [
    "# Plots for Ground Truth Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e8de1a",
   "metadata": {},
   "source": [
    "## Plots vs $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b6e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem\n",
    "from visualization import plot_metrics_vs_param\n",
    "\n",
    "# === Load the experiment results ===\n",
    "with open(\"Data_final/gt_scan_s5_Ksweep_pSweep_n1000.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "print(\"✅ Results successfully loaded from Data_final/gt_scan_s5_Ksweep_pSweep_n1000.pkl\")\n",
    "\n",
    "# === Filter experiments for specific K values ===\n",
    "K_values = [1, 4, 9]\n",
    "results_subset = [res for res in results if res['params']['K'] in K_values]\n",
    "\n",
    "# === Plot: GT accuracy vs p, grouped by K ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results_subset,\n",
    "    param_x=\"p\",\n",
    "    metrics=[\"gt_accuracy\"],\n",
    "    group_by=\"K\",\n",
    "    sub_plot=True,\n",
    "    log_scale_x=True,\n",
    "    font_scale=1.5,\n",
    "    save_path=\"Results_final/gt_accuracy_vs_K\"\n",
    ")\n",
    "\n",
    "# === Function to aggregate accuracy SEM by a parameter ===\n",
    "def aggregate_by_param(results, param_key):\n",
    "    \"\"\"\n",
    "    Aggregates mean accuracy and SEM by the given parameter.\n",
    "    \"\"\"\n",
    "    param_values = sorted(set(res['params'][param_key] for res in results))\n",
    "    means, errors = [], []\n",
    "    for val in param_values:\n",
    "        accs = [np.mean(res['results']['gt_accuracy']) for res in results if res['params'][param_key] == val]\n",
    "        means.append(np.mean(accs))\n",
    "        errors.append(sem(accs))\n",
    "    return param_values, means, errors\n",
    "\n",
    "# === Plot: GT error (SEM on accuracy) vs p in log-scale ===\n",
    "p_vals, _, p_sems = aggregate_by_param(results, 'p')\n",
    "font_scale = 1.5\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(p_vals, p_sems, 'd-', label=\"SEM of GT Accuracy\")\n",
    "plt.title(\"GT Error vs $p$\", fontsize=14 * font_scale)\n",
    "plt.xlabel(\"$p$\", fontsize=12 * font_scale)\n",
    "plt.ylabel(\"Error on Accuracy\", fontsize=12 * font_scale)\n",
    "plt.xscale('log')\n",
    "plt.xticks(fontsize=10 * font_scale)\n",
    "plt.yticks(fontsize=10 * font_scale)\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Results_final/gt_error_vs_p.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deffbda9",
   "metadata": {},
   "source": [
    "## Plots vs $d$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ce82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from visualization import plot_metrics_vs_param\n",
    "\n",
    "# === Load the experiment results ===\n",
    "with open(\"Data_final/scan_d_s_gt.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "print(\"✅ Results successfully loaded from Data_final/scan_d_s_gt.pkl\")\n",
    "\n",
    "# === Plot: GT accuracy vs d, grouped by s ===\n",
    "plot_metrics_vs_param(\n",
    "    results=results,\n",
    "    param_x=\"d\",\n",
    "    metrics=[\"gt_accuracy\"],\n",
    "    group_by=\"s\",\n",
    "    save_path=\"Results_final/gt_accuracy_d_vs_s.png\",\n",
    "    ylim=(0.5, 1),\n",
    "    font_scale=1.5,\n",
    "    # log_scale_x=True  # Uncomment if log scale is desired\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Semester_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
